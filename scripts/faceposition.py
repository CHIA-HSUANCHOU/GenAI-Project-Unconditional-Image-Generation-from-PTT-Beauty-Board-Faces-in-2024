# -*- coding: utf-8 -*-
"""faceposition_submit

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CTwCyU704vGXZviPXrkgr0lEqzgnJgRu
"""

# æ›è¼‰ Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
import cv2
import numpy as np
import zipfile
import shutil
from tqdm import tqdm
from collections import defaultdict
from insightface.app import FaceAnalysis
import matplotlib.pyplot as plt
import csv

# è¨­å®šè·¯å¾‘
zip_root = "/content/drive/MyDrive/image_ppt/"
temp_extract = "/content/temp_unzip"
final_output = "/content/drive/MyDrive/positionface"
os.makedirs(final_output, exist_ok=True)

# åˆå§‹åŒ– InsightFace
app = FaceAnalysis(name="buffalo_l", providers=["CUDAExecutionProvider"])
app.prepare(ctx_id=0, det_size=(640, 640))

"""## é‡æ–°è£ä¸€é=>å°é½Š=>å·¦å³è‡‰=>å†è£64*64"""

# è¨­å®šè·¯å¾‘
zip_root = "/content/drive/MyDrive/image_ppt/"
temp_extract = "/content/temp_unzip"
output_dir = "/content/drive/MyDrive/positioned_faces"
os.makedirs(output_dir, exist_ok=True)

# åƒæ•¸è¨­å®š
sharpness_threshold = 60.0
resize_size = (256, 256)
face_margin = 0.50
face_idx = 1

# å°‡ zip æª”æ¡ˆä¾ç…§æœˆä»½åˆ†çµ„
month_groups = defaultdict(list)
for fname in os.listdir(zip_root):
    if fname.endswith(".zip") and "images_" in fname:
        parts = fname.split("_")
        month = parts[1]  # 01, 02, etc.
        month_groups[month].append(fname)

from collections import defaultdict

# çµ±è¨ˆåˆå§‹åŒ–
count_stats = defaultdict(int)

# åªè™•ç†ä¸€æœˆ
month = "01"
face_idx = 1
print(f"ğŸ“¦ è™•ç†æœˆä»½ {month} å…± {len(month_groups[month])} åŒ…")

for zip_name in tqdm(sorted(month_groups[month])):
    zip_path = os.path.join(zip_root, zip_name)
    if os.path.exists(temp_extract):
         shutil.rmtree(temp_extract)

    os.makedirs(temp_extract, exist_ok=True)

    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(temp_extract)

    image_files = sorted([
        f for f in os.listdir(temp_extract)
        if f.lower().endswith(('.jpg', '.jpeg', '.png'))
    ])

    for fname in image_files:
        in_path = os.path.join(temp_extract, fname)
        img = cv2.imread(in_path)
        if img is None:
            print(f"{fname}: è®€å–å¤±æ•—")
            continue

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
        reason = None
        cropped = None
        resized = None
        aligned = None
        gender_str = "Unknown"

        if sharpness < sharpness_threshold:
            reason = f"sharpness too low: {sharpness:.2f}"
        else:
            faces = app.get(img)

            if len(faces) == 0:
                reason = "no face detected"
                continue
            else:
                face = max(faces, key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]))
                if not hasattr(face, "kps") or face.kps is None or np.isnan(face.kps).any():
                    reason = "occlusion"
                    continue

                x1, y1, x2, y2 = face.bbox.astype(int)
                face_area = (x2 - x1) * (y2 - y1)
                img_area = img.shape[0] * img.shape[1]
                if face_area / img_area < 0.015:
                    reason = "face too small (pre-align)"
                else:
                # å°é½Š
                    left_eye, right_eye = face.kps[0], face.kps[1]
                    dx, dy = right_eye[0] - left_eye[0], right_eye[1] - left_eye[1]
                    angle = np.degrees(np.arctan2(dy, dx))
                    eyes_center = (float(left_eye[0] + right_eye[0]) / 2, float(left_eye[1] + right_eye[1]) / 2)
                    M = cv2.getRotationMatrix2D(eyes_center, angle, 1)
                # è¨­å®š canvas å°ºå¯¸ç‚ºåŸåœ–çš„ 1.2 å€
                    h, w = img.shape[:2]
                    scale_factor = 1.2
                    new_w, new_h = int(w * scale_factor), int(h * scale_factor)

                    aligned = cv2.warpAffine(
                    img, M, (new_w, new_h),
                    flags=cv2.INTER_LINEAR,
                    borderMode=cv2.BORDER_REPLICATE  # ä¹Ÿå¯ä»¥è©¦ BORDER_REPLICATE
                    )

                # é‡æ–°åµæ¸¬è‡‰ï¼ˆç”¨æ–¼ cropï¼‰
                    new_faces = app.get(aligned)
                    if len(new_faces) == 0:
                        reason = "no face found even in original"
                        face = max(faces, key=lambda f: (f.bbox[2]-f.bbox[0])*(f.bbox[3]-f.bbox[1]))
                        working_img = img
                    else:
                        face = max(new_faces, key=lambda f: (f.bbox[2]-f.bbox[0])*(f.bbox[3]-f.bbox[1]))
                        working_img = aligned
                    x1, y1, x2, y2 = face.bbox.astype(int)
                    w, h = x2 - x1, y2 - y1
                    face_area = (x2 - x1) * (y2 - y1)
                    img_area = working_img.shape[0] * working_img.shape[1]
                    if face_area / img_area < 0.015:
                        reason = "face too small (after align)"
                    else:
                        cx, cy = x1 + w // 2, y1 + h // 2
                        size = int(max(w, h) * (1 + face_margin))
                        x1_new = max(0, cx - size // 2)
                        y1_new = max(0, cy - size // 2)
                        x2_new = min(working_img.shape[1], cx + size // 2)
                        y2_new = min(working_img.shape[0], cy + size // 2)
                        cropped = working_img[y1_new:y2_new, x1_new:x2_new]
                        if cropped.size > 0:
                            # === æ–°å¢ï¼šèƒŒæ™¯æ¨¡ç³Šè™•ç† ===
                        # ç”Ÿæˆæ¨¡ç³ŠèƒŒæ™¯ç‰ˆæœ¬
                            blurred = cv2.GaussianBlur(cropped, (31, 31), 0)

                        # ç”Ÿæˆåœ“å½¢ feather maskï¼ˆè‡‰éƒ¨ä¿ç•™ï¼‰
                            h_crop, w_crop = cropped.shape[:2]
                            mask = np.zeros((h_crop, w_crop), dtype=np.uint8)
                            center = (w_crop // 2, h_crop // 2)
                            radius = int(min(w_crop, h_crop) * 0.55)
                            cv2.circle(mask, center, radius, 255, -1)

                           # feather é‚Šç•Œ
                            mask = cv2.GaussianBlur(mask, (21, 21), 0).astype(np.float32) / 255.0
                            mask_3ch = np.repeat(mask[..., None], 3, axis=2)

                           # å°‡è‡‰éƒ¨å€åŸŸä¿ç•™ï¼ŒèƒŒæ™¯æ¨¡ç³Šèåˆ
                            blended = (cropped.astype(np.float32) * mask_3ch +
                            blurred.astype(np.float32) * (1 - mask_3ch)).astype(np.uint8)

                            resized = cv2.resize(blended, resize_size, interpolation=cv2.INTER_AREA)

                            yaw = face.pose[1]
                            if abs(yaw) < 20:
                                pos = "frontal"
                            elif yaw < -20:
                                pos = "left"
                            else:
                                pos = "right"

                            if face.gender not in [0, 1]:
                                gender_str = "Female"  # å°‡ unknown ç•¶ä½œ Female
                            else:
                                gender_str = "Male" if face.gender == 1 else "Female"

                            output_subdir = os.path.join(output_dir, gender_str, pos)


                            base_name = f"{month}_{os.path.splitext(os.path.basename(fname))[0]}"
                            if reason and "occlusion" in reason:
                                base_name += "_occluded"
                            base_name += ".png"

                            out_path = os.path.join(output_subdir, base_name)
                            cv2.imwrite(out_path, resized)
                            count_stats[(gender_str, pos)] += 1

# é¡¯ç¤ºçµ±è¨ˆçµæœ
total_faces = sum(count_stats.values())
print(f"âœ… æœˆä»½ {month} è™•ç†å®Œç•¢ï¼Œå…±ç”¢ç”Ÿ {total_faces} å¼µäººè‡‰åœ–ç‰‡")
print("\nğŸ“Š Gender/Face Pose åˆ†é¡çµ±è¨ˆï¼š")
for gender in ["Male", "Female"]:
    for pose in ["frontal", "left", "right"]:
        print(f"{gender} - {pose}: {count_stats[(gender, pose)]} å¼µ")

for m in range(2, 13):
    month = f"{m:02d}"
    face_idx = 1
    print(f"\nğŸ“¦ è™•ç†æœˆä»½ {month} å…± {len(month_groups[month])} åŒ…")

    for zip_name in tqdm(sorted(month_groups[month])):
        zip_path = os.path.join(zip_root, zip_name)
        if os.path.exists(temp_extract):
            shutil.rmtree(temp_extract)

        os.makedirs(temp_extract, exist_ok=True)

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_extract)

        image_files = sorted([
            f for f in os.listdir(temp_extract)
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ])

        for fname in image_files:
            in_path = os.path.join(temp_extract, fname)
            img = cv2.imread(in_path)
            if img is None:
                print(f"{fname}: è®€å–å¤±æ•—")
                continue

            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            reason = None
            cropped = None
            resized = None
            aligned = None
            gender_str = "Unknown"

            if sharpness < sharpness_threshold:
                reason = f"sharpness too low: {sharpness:.2f}"
            else:
                faces = app.get(img)
                if len(faces) == 0:
                    reason = "no face detected"
                    continue
                else:
                    face = max(faces, key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]))
                    if not hasattr(face, "kps") or face.kps is None or np.isnan(face.kps).any():
                        reason = "occlusion"
                        continue

                    x1, y1, x2, y2 = face.bbox.astype(int)
                    face_area = (x2 - x1) * (y2 - y1)
                    img_area = img.shape[0] * img.shape[1]
                    if face_area / img_area < 0.015:
                        reason = "face too small (pre-align)"
                    else:
                        left_eye, right_eye = face.kps[0], face.kps[1]
                        dx, dy = right_eye[0] - left_eye[0], right_eye[1] - left_eye[1]
                        angle = np.degrees(np.arctan2(dy, dx))
                        eyes_center = ((left_eye[0] + right_eye[0]) / 2, (left_eye[1] + right_eye[1]) / 2)
                        M = cv2.getRotationMatrix2D(eyes_center, angle, 1)

                        h, w = img.shape[:2]
                        scale_factor = 1.2
                        new_w, new_h = int(w * scale_factor), int(h * scale_factor)

                        aligned = cv2.warpAffine(
                            img, M, (new_w, new_h),
                            flags=cv2.INTER_LINEAR,
                            borderMode=cv2.BORDER_REPLICATE
                        )

                        new_faces = app.get(aligned)
                        if len(new_faces) == 0:
                            reason = "no face found even in original"
                            face = max(faces, key=lambda f: (f.bbox[2]-f.bbox[0])*(f.bbox[3]-f.bbox[1]))
                            working_img = img
                        else:
                            face = max(new_faces, key=lambda f: (f.bbox[2]-f.bbox[0])*(f.bbox[3]-f.bbox[1]))
                            working_img = aligned

                        x1, y1, x2, y2 = face.bbox.astype(int)
                        w, h = x2 - x1, y2 - y1
                        face_area = (x2 - x1) * (y2 - y1)
                        img_area = working_img.shape[0] * working_img.shape[1]
                        if face_area / img_area < 0.015:
                            reason = "face too small (after align)"
                        else:
                            cx, cy = x1 + w // 2, y1 + h // 2
                            size = int(max(w, h) * (1 + face_margin))
                            x1_new = max(0, cx - size // 2)
                            y1_new = max(0, cy - size // 2)
                            x2_new = min(working_img.shape[1], cx + size // 2)
                            y2_new = min(working_img.shape[0], cy + size // 2)
                            cropped = working_img[y1_new:y2_new, x1_new:x2_new]
                            if cropped.size > 0:
                                blurred = cv2.GaussianBlur(cropped, (31, 31), 0)

                                h_crop, w_crop = cropped.shape[:2]
                                mask = np.zeros((h_crop, w_crop), dtype=np.uint8)
                                center = (w_crop // 2, h_crop // 2)
                                radius = int(min(w_crop, h_crop) * 0.55)
                                cv2.circle(mask, center, radius, 255, -1)

                                mask = cv2.GaussianBlur(mask, (21, 21), 0).astype(np.float32) / 255.0
                                mask_3ch = np.repeat(mask[..., None], 3, axis=2)

                                blended = (cropped.astype(np.float32) * mask_3ch +
                                           blurred.astype(np.float32) * (1 - mask_3ch)).astype(np.uint8)

                                resized = cv2.resize(blended, resize_size, interpolation=cv2.INTER_AREA)

                                yaw = face.pose[1]
                                if abs(yaw) < 20:
                                    pos = "frontal"
                                elif yaw < -20:
                                    pos = "left"
                                else:
                                    pos = "right"

                                if face.gender not in [0, 1]:
                                    gender_str = "Female"
                                else:
                                    gender_str = "Male" if face.gender == 1 else "Female"

                                output_subdir = os.path.join(output_dir, gender_str, pos)
                                os.makedirs(output_subdir, exist_ok=True)

                                base_name = f"{month}_{os.path.splitext(os.path.basename(fname))[0]}"
                                if reason and "occlusion" in reason:
                                    base_name += "_occluded"
                                base_name += ".png"

                                out_path = os.path.join(output_subdir, base_name)
                                cv2.imwrite(out_path, resized)
                                count_stats[(gender_str, pos)] += 1

    total_faces = sum(count_stats.values())
    print(f"âœ… æœˆä»½ {month} è™•ç†å®Œç•¢ï¼Œå…±ç”¢ç”Ÿ {total_faces} å¼µäººè‡‰åœ–ç‰‡")
    print("\nğŸ“Š Gender/Face Pose åˆ†é¡çµ±è¨ˆï¼š")
    for gender in ["Male", "Female"]:
        for pose in ["frontal", "left", "right"]:
            print(f"{gender} - {pose}: {count_stats[(gender, pose)]} å¼µ")